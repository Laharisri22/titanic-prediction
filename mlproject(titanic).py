# -*- coding: utf-8 -*-
"""mlproject(titanic).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ji--6rbdiKHihV4UJeqYq5fex9Fjfk8N
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

!pip install pyforest

import pyforest

data=pd.read_csv("Titanic-Dataset.csv")
data.head()

data.shape

data.dtypes

data.drop(["Name","Ticket","Cabin"],axis=1,inplace=True)

data.isnull().sum()

data.head()

data.info()

data.describe()

"""label encoder  chnages strings to numbers so that machine can understand easily

fit() → learns something from the data

example: mean, standard deviation, min, max, vocabulary, etc.

transform() → uses what it learned to change the data

fit_transform() does two things together
"""

from sklearn import preprocessing
label_encoder=preprocessing.LabelEncoder()
data["Sex"]=label_encoder.fit_transform(data["Sex"])
data["Sex"].value_counts()

data

data.fillna(value=data["Age"].median(),inplace=True)#filling age value by meadian
data.head()

import numpy as np
data["Embarked"] = data["Embarked"].replace(28.0, np.nan)

data.isna().sum()

data["Age"].isna().sum()

data["Embarked"].isna().sum()

data["Embarked"].value_counts()

g=data.groupby("Survived")
print(g["Embarked"].value_counts())

import pandas as pd

data = pd.read_csv("Titanic-Dataset.csv")

# correct filling
data["Age"].fillna(data["Age"].median(), inplace=True)
data["Embarked"].fillna(data["Embarked"].mode()[0], inplace=True)#Mode = value that appears the most
data.drop(["Name","Ticket","Cabin"],axis=1,inplace=True)
data

data["Embarked"].value_counts()

data

from sklearn import preprocessing
label_encoder=preprocessing.LabelEncoder()
data["Sex"]=label_encoder.fit_transform(data["Sex"])
data["Sex"].value_counts()

from sklearn import preprocessing
label_encode=preprocessing.LabelEncoder()
data["Embarked"]=label_encode.fit_transform(data["Embarked"])
data["Embarked"].value_counts()

sns.countplot(x=data["Embarked"],hue=data["Survived"])
plt.show()

data.corr()

data.plot(x="Survived",y=["SibSp","Parch"],kind="bar")
#It draws a bar chart to compare SibSp and Parch values based on Survived.
#This code draws a bar graph showing how many family members people had, based on whether they survived or not.
plt.show()

corelation=data.corr()
#This code tells us which columns are most important for survival, ordered from most important to least.
corelation["Survived"].sort_values(ascending=False)

sns.heatmap(data.corr())
##This heat map shows which factors helped people survive on the Titanic and which did not, using colors to show strength of relationships.

corelation["Fare"].sort_values(ascending=False)
corelation["Fare"]

data.head()

data["Family"]=data["SibSp"]+data["Parch"]+1

data.drop(["SibSp","Parch"],axis=1,inplace=True)

data.drop(["PassengerId","Embarked"],axis=1,inplace=True)

data

"""# **sci-kitlearn traing and spliting data**"""

X = data.drop("Survived", axis=1)
y = data["Survived"]

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

from sklearn.linear_model import LogisticRegression

lr = LogisticRegression(max_iter=1000)
lr.fit(X_train, y_train)

from sklearn.metrics import accuracy_score

data.head()

new_passenger = [[
    3,    # Pclass
    1,    # Sex (0 = female)
    22,   # Age
    7.2, # Fare
    2     # Family
]]


lrpred = lr.predict(new_passenger)

print("Survived" if lrpred[0] == 1 else "Not Survived")

accuracy_score(y_test,lrpred)

from sklearn.model_selection import GridSearchCV
import numpy as np

c_space = np.logspace(-5, 8, 15)
param_grid = {"C": c_space}

logreg_cv = GridSearchCV(lr, param_grid, cv=5)

# ❗ THIS LINE WAS MISSING
logreg_cv.fit(X_train, y_train)

print("Tuned Logistic Regression C value:", logreg_cv.best_params_)

